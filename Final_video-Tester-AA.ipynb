{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["\n\n<br>\n", "#19436795<br>\n", "#University of Northampton<br>\n", "#Assignment-1 <br>\n", ""]}, {"cell_type": "markdown", "metadata": {}, "source": ["mported the required libraries"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import os\n", "import cv2\n", "import numpy as nummp\n", "from keras.models import model_from_json\n", "from keras.preprocessing import image"]}, {"cell_type": "markdown", "metadata": {}, "source": ["he models are loaded to the fer.json file"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["model = model_from_json(open(\"fer.json\", \"r\").read())\n", "#it predicts the emotions based on the phases particularly\n", "model.load_weights('fer.h5')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["ace classifier detects the face from the input frame"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["fac_har_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["his is used for capturing the video from web camera<br>\n", "he passed 0 uses the web camera by default"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["captu=cv2.VideoCapture(0)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["his infinte loop continues till the users termiates the execution"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["while True:\n", "    #this takes the video's single frame which takes the object\n", "    rett,test_imaag=captu.read()# captures frame and returns boolean value and captured image\n", "    if not rett:\n", "        continue\n", "    #the captured video is converted into gray scale\n", "    #the gray scale is changed to face classifiers\n", "    gray_img= cv2.cvtColor(test_imaag, cv2.COLOR_BGR2GRAY)\n\n", "    #this method will detect the face from that specific images\n", "    #data is stored in the following \n", "    facemo_detected = fac_har_cascade.detectMultiScale(gray_img, 1.3, 5)\n\n", "    #it returns the following four variables\n", "    for (a,b,w,h) in facemo_detected:\n", "        #the following makes a rectangle boundry around the face after detection\n", "        cv2.rectangle(test_imaag,(a,b),(a+w,b+h),(255,223,155),thickness=7) # size of the boundry \n", "        ro_gray=gray_img[b:b+w,a:a+h]#cropping face area from  image\n", "        \n", "        #this dimension is standard\n", "        ro_gray=cv2.resize(ro_gray,(48,48))\n", "        \n", "        #the image is converted to array\n", "        imaag_pixels = image.img_to_array(ro_gray)\n", "        imaag_pixels = nummp.expand_dims(imaag_pixels, axis = 0)\n", "        imaag_pixels /= 255\n\n", "        #the following predicts the probanility of the classes\n", "        predicts = model.predict(imaag_pixels)\n\n", "        #find the max indexed array or the maximum possible emotion\n", "        mx_index = nummp.argmax(predicts[0])\n\n", "        #emotions labled in array for the detection\n", "        emotional = ['angry', 'disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral']\n", "        \n", "        pred_emotion = emotional[mx_index]\n\n", "        #text on the video boundry, shows the emotion text made by the user\n", "        cv2.putText(test_imaag, pred_emotion, (int(a), int(b)), cv2.FONT_HERSHEY_SIMPLEX, 1, (144,255,190), 2) #size of the text\n\n", "    #for the size of the image\n", "    resiz_img = cv2.resize(test_imaag, (1000, 700))\n", "    \n", "    #for showing the whole running program\n", "    cv2.imshow('Facial Emotion Detecting Software ',resiz_img)\n", "    "]}, {"cell_type": "markdown", "metadata": {}, "source": ["or closing the window "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    if cv2.waitKey(10) == ord('g'):#'g' key when pressed terminates the running program\n", "        break"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["captu.release()\n", "#releasing task for destroying the other window\n", "cv2.destroyAllWindows"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}